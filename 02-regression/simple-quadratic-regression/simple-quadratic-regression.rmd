`r opts_chunk$set(cache=TRUE)`

$$latex y_i \sim N(\beta_0  + \beta_1 x_i  + \beta_2  x_i^2, \sigma^2)$$



```{r message=FALSE}
rm(list=ls())
require(rjags)
require(coda)
library(xtable)
```


# Generate data
```{r}
set.seed(4444)
Beta0 <- 2
Beta1 <- 8
Beta2 <- -0.8
N <- 100
Sigma <- 5
    
x <- runif(n=N, min=0, max=10) 
y <- Beta0 + Beta1 * x + Beta2 * x^2 + rnorm(n=N, mean=0, sd=Sigma)
Data <- list(x=x,  y=y)
```

# Non-Bayesian analysis
```{r}
lmfit <- lm(y~x+I(x^2))
summary(lmfit)
plot(x, y)
lines(x[order(x)], predict(lmfit)[order(x)], col="blue") # add fit line
```

# Define JAGS model
```{r}
jags.script <- "
model{
    # likelihood
    for( i in 1:length(x[])) {
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- beta0 + beta1 * x[i] + beta2 * pow(x[i], 2)
    }

    # priors
    beta0 ~ dnorm(0.0, 1.0E-6)
    beta1  ~ dnorm(0.0, 1.0E-6)
    beta2  ~ dunif(-10000, -0.01) # exclude zero to permit turning point
    tau  ~ dgamma(0.1,0.1)

    # transformations
    sigma <- pow(tau, 0.5)
    delta <- (0 - beta1) / (2 * beta2)
}
" 
```

# Perform Bayesian analysis using JAGS
```{r}
jags.fit <- jags.model(textConnection(jags.script), 
                       data=Data, n.chains=4, n.adapt=1000)

update(jags.fit, n.iter=1000) # burnin

jags.samples <- coda.samples(model=jags.fit,
                             variable.names=c('beta0', 'beta1', 
                                              'beta2', 'sigma', 'delta'),
                             n.iter=2000)
plot(jags.samples)
summary(jags.samples) 
```

# Compare model predictions
(a) means of posteriors of parameters
(b) least squares estimates of parameters

```{r}
beta0.posterior.mean <- summary(jags.samples)$statistics["beta0", "Mean"]
beta1.posterior.mean <- summary(jags.samples)$statistics["beta1", "Mean"]
beta2.posterior.mean <- summary(jags.samples)$statistics["beta2", "Mean"]

plot(x, y)
ypred <- beta0.posterior.mean + beta1.posterior.mean*x + 
    beta2.posterior.mean*x^2
lines(x[order(x)], ypred[order(x)], col="red")
lines(x[order(x)], predict(lmfit)[order(x)], col="blue") # add fit line
abline(v=summary(jags.samples)$statistics['delta', 'Mean']) # turning point
legend(x=8, y=4, legend=c("posterior mean", "lm fit"), 
       col=c("red", "blue"), lty=1)
```


# Examine predictions
This is based on sampling values of predicted y (i.e., mu)
However, I'm not sure if this is correct ways to generate predictions from the posterior.
```{r}
jags.predictions <- coda.samples(model=jags.fit,
                                                 variable.names=c('mu'),
                                                 n.iter=1000)
jags.predictions.summary <- summary(jags.predictions)

plot(x, y)
lines(x[order(x)], jags.predictions.summary$statistics[, "Mean"][order(x)])
lines(x[order(x)], jags.predictions.summary$quantiles[, "2.5%"][order(x)], lty=2)
lines(x[order(x)], jags.predictions.summary$quantiles[, "97.5%"][order(x)], lty=2)
legend(x=8, y=4, legend=c("2.5%", "Mean", "97.5%"), lty=c(2,1,2))
```


# Compare Bayesian with lm approach
```{r results='asis'}
# Examine correlation between parameter estimates
# lag0 correlation between parameter estimates
auto0 <- round(autocorr(jags.samples)[[1]][1, , ], 2)

auto0[!lower.tri(auto0)] <-""

print(xtable(auto0), type="html")
```


```{r}
round(cov2cor(vcov(lmfit)), 2) # compare with linear model
```

The correlation between parameters in the posterior and the correlations of parameters estimates in the least squares analysis are almost identical in this instance.


```{r}
# Parameter estimates
sprintf("Beta0=%.2f; Beta1=%.2f; Beta2=%.2f", Beta0, Beta1, Beta2) # true data generating values
summary(jags.samples)$statistics # Mean and SD of posterior
coef(summary(lmfit)) #expected and standard error of linear model parameter estimates
stem(jags.samples[[1]][,'delta'])
```


# Explore mean centering
Mean centering is a way of reducing the auto-correlation in the MCMC chain.

Thus, we can specify a model as follows:

$latex y_i \sim N(\gamma_0 + \gamma_1 z_i + \gamma_2 z_i^2, \sigma^2)$ where $latex z_i = x_i - \bar{x}$.

## Define JAGS model
```{r}
jags.script.centered <- "
model{
    # likelihood
    for( i in 1:length(x[])) {
        z[i] <- x[i] - mean(x)
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- gamma0 + gamma1 * z[i] + gamma2 * pow(z[i], 2)
    }

    # priors
    gamma0 ~ dnorm(0.0, 1.0E-6)
    gamma1  ~ dnorm(0.0, 1.0E-6)
    gamma2  ~ dunif(-10000, -0.01) # exclude zero to permit turning point
    tau  ~ dgamma(0.1,0.1)

    # transformations
    sigma <- pow(tau, 0.5)
    
    
    # delta <- (0 - beta1) / (2 * beta2)
}
" 
```

# Perform Bayesian analysis using JAGS
```{r}
jags.fit.centered <- jags.model(textConnection(jags.script.centered), 
                       data=Data, n.chains=4, n.adapt=1000)

update(jags.fit.centered, n.iter=1000) # burnin

jags.samples <- coda.samples(model=jags.fit.centered,
                             variable.names=c('gamma0', 'gamma1', 
                                              'gamma2', 'sigma'),
                             n.iter=2000)
plot(jags.samples)
summary(jags.samples) 
```
